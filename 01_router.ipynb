{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MANUAL', 'PORT', 'Rules']\n",
      "['ABS', 'Cryostar', 'Win GD', 'KR', 'Port Regulation', 'Integrated Smart Ship(ISS)', 'BV', 'DNV', 'LR', 'MARPOL', 'NK', 'SOLAS', 'Common']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vectordb, vectorstore, MANUAL, PORT, Rules, ABS, Cryostar, Win GD, KR, Port Regulation, Integrated Smart Ship(ISS), BV, DNV, LR, MARPOL, NK, SOLAS, Common'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectordb_targets(db_path:str):\n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "    for collection in client.list_collections():\n",
    "        data = collection.get(include=['metadatas'])\n",
    "    lv1 = list(set([d['First Division'] for d in data[\"metadatas\"]]))\n",
    "    print(lv1)\n",
    "    lv2 = list(set([d['Second Division'] for d in data[\"metadatas\"]]))\n",
    "    print(lv2)\n",
    "    rag_target = lv1 + lv2\n",
    "    rag_target.insert(0, \"vectorstore\")\n",
    "    rag_target.insert(0, \"vectordb\")\n",
    "    docs = \", \".join(rag_target)\n",
    "    return docs\n",
    "\n",
    "db_path = \"./db/chroma_db_02\"\n",
    "docs = vectordb_targets(db_path=db_path)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"similarity_search\", \"vectorstore\", \"web_search\", \"database\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore or a similarity or a database.\",\n",
    "    )\n",
    "\n",
    "# Prompt\n",
    "system = f\"\"\"You are an expert at routing a user question to a vectorstore, web search or database.\n",
    "The vectorstore contains documents related to {docs}, Use the vectorstore for questions on these topics. \n",
    "The question contains words of similarity or sim search, Use similarity_search for the question.\n",
    "The question contains words related to database, Use the database for the question. \n",
    "Otherwise, use web-search.\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert at routing a user question to a vectorstore, web search or database.\\nThe vectorstore contains documents related to vectordb, vectorstore, MANUAL, PORT, Rules, ABS, Cryostar, Win GD, KR, Port Regulation, Integrated Smart Ship(ISS), BV, DNV, LR, MARPOL, NK, SOLAS, Common, Use the vectorstore for questions on these topics. \\nThe question contains words of similarity or sim search, Use similarity_search for the question.\\nThe question contains words related to database, Use the database for the question. \\nOtherwise, use web-search.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000026A79E02A20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000026A79E03A40>, model_name='llama-3.2-11b-text-preview', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'RouteQuery', 'description': 'Route a user query to the most relevant datasource.', 'parameters': {'properties': {'datasource': {'description': 'Given a user question choose to route it to web search or a vectorstore or a similarity or a database.', 'enum': ['similarity_search', 'vectorstore', 'web_search', 'database'], 'type': 'string'}}, 'required': ['datasource'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'RouteQuery'}}}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.RouteQuery'>])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(temperature=0, model_name= \"llama-3.2-11b-text-preview\")\n",
    "# llm = ChatOllama(base_url=\"http://localhost:11434\", model=\"llama3.2:latest\")\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "question_router = route_prompt | structured_llm_router\n",
    "question_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n",
      "datasource='database'\n",
      "datasource='vectorstore'\n",
      "datasource='web_search'\n",
      "datasource='similarity_search'\n",
      "datasource='similarity_search'\n"
     ]
    }
   ],
   "source": [
    "print(question_router.invoke({\"question\": \"who is Son Heung-min\"}))\n",
    "print(question_router.invoke({\"question\": \"according to database, who is Son Heung-min\"}))\n",
    "print(question_router.invoke({\"question\": \"according to vectordb, who is Son Heung-min\"}))\n",
    "print(question_router.invoke({\"question\": \"check the recent performance data of Son Heung min\"}))\n",
    "print(question_router.invoke({\"question\": \"sim search for this sentence. who is Son Heung-min\"}))\n",
    "print(question_router.invoke({\"question\": \"find similar sentences for this sentence. who is Son Heung-min\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "query = 'with reference to \"lr\" rule, explain the measurement procedure of \"noise\"'\n",
    "print(question_router.invoke({\"question\": query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='similarity_search'\n"
     ]
    }
   ],
   "source": [
    "query = 'similarity search for this. with reference to \"lr\" rule, explain the measurement procedure of \"noise\"'\n",
    "print(question_router.invoke({\"question\": query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
