{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PORT', 'MANUAL', 'Rules']\n",
      "['Integrated Smart Ship(ISS)', 'Cryostar', 'ABS', 'MARPOL', 'LR', 'NK', 'KR', 'Common', 'Win GD', 'Port Regulation', 'DNV', 'BV', 'SOLAS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vectordb, vectorstore, PORT, MANUAL, Rules, Integrated Smart Ship(ISS), Cryostar, ABS, MARPOL, LR, NK, KR, Common, Win GD, Port Regulation, DNV, BV, SOLAS'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 벡터DB 종류에 따라 수정 필요\n",
    "\n",
    "def vectordb_targets(db_path:str):\n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "    for collection in client.list_collections():\n",
    "        data = collection.get(include=['metadatas'])\n",
    "    lv1 = list(set([d['First Division'] for d in data[\"metadatas\"]]))\n",
    "    print(lv1)\n",
    "    lv2 = list(set([d['Second Division'] for d in data[\"metadatas\"]]))\n",
    "    print(lv2)\n",
    "    rag_target = lv1 + lv2\n",
    "    rag_target.insert(0, \"vectorstore\")\n",
    "    rag_target.insert(0, \"vectordb\")\n",
    "    docs = \", \".join(rag_target)\n",
    "    return docs\n",
    "\n",
    "db_path = \"./db/chroma_db_02\"\n",
    "db_index = vectordb_targets(db_path=db_path)\n",
    "db_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class RouteState(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "    datasource: Literal[\"similarity_search\", \"vectorstore\", \"web_search\", \"database\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore or a similarity or a database.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert at routing a user question to a vectorstore, web search or database.\\n    The vectorstore contains documents related to vectordb, vectorstore, PORT, MANUAL, Rules, Integrated Smart Ship(ISS), Cryostar, ABS, MARPOL, LR, NK, KR, Common, Win GD, Port Regulation, DNV, BV, SOLAS, Use the vectorstore for questions on these topics. \\n    The question contains words of similarity or sim search, Use similarity_search for the question.\\n    The question contains words related to database, Use the database for the question. \\n    Otherwise, use web-search.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000155CA650A70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000155CA651580>, model_name='llama-3.3-70b-versatile', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'RouteState', 'description': 'Route a user query to the most relevant datasource.', 'parameters': {'properties': {'datasource': {'description': 'Given a user question choose to route it to web search or a vectorstore or a similarity or a database.', 'enum': ['similarity_search', 'vectorstore', 'web_search', 'database'], 'type': 'string'}}, 'required': ['datasource'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'RouteState'}}}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.RouteState'>])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def routing_agent(state):\n",
    "    global db_index\n",
    "\n",
    "    system = f\"\"\"You are an expert at routing a user question to a vectorstore, web search or database.\n",
    "    The vectorstore contains documents related to {db_index}, Use the vectorstore for questions on these topics. \n",
    "    The question contains words of similarity or sim search, Use similarity_search for the question.\n",
    "    The question contains words related to database, Use the database for the question. \n",
    "    Otherwise, use web-search.\"\"\"\n",
    "\n",
    "    route_prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\"),])\n",
    "    \n",
    "    llm = ChatGroq(temperature=0, model_name= \"llama-3.3-70b-versatile\")    \n",
    "\n",
    "    structured_llm_router = llm.with_structured_output(state)\n",
    "    question_router = route_prompt | structured_llm_router\n",
    "    return question_router\n",
    "\n",
    "question_router = routing_agent(state=RouteState)\n",
    "question_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "query = 'with reference to \"lr\" rule, explain the measurement procedure of \"noise\"'\n",
    "print(question_router.invoke({\"question\": query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n",
      "datasource='database'\n",
      "datasource='vectorstore'\n",
      "datasource='web_search'\n",
      "datasource='similarity_search'\n",
      "datasource='similarity_search'\n"
     ]
    }
   ],
   "source": [
    "questions = [\"who is Son Heung-min\",\n",
    "             \"according to database, who is Son Heung-min\",\n",
    "             \"according to vectordb, who is Son Heung-min\",\n",
    "             \"check the recent performance data of Son Heung min\",\n",
    "             \"sim search for this sentence. who is Son Heung-min\",\n",
    "             \"find similar sentences for this sentence. who is Son Heung-min\"]\n",
    "\n",
    "for question in questions:\n",
    "    result = question_router.invoke({'question': question})\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
