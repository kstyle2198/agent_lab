{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = str(uuid.uuid4())\n",
    "\n",
    "# The value needs to be a dictionary  \n",
    "value = {\"food_preference\" : \"I like pizza\"}\n",
    "\n",
    "# Save the memory\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search \n",
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "type(memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metatdata \n",
    "memories[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key, value\n",
    "print(memories[0].key, memories[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the memory by namespace and key\n",
    "memory = in_memory_store.get(namespace_for_memory, key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(temperature=0, model_name= \"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"\"You are collecting information about the user to personalize your responses.\n",
    "\n",
    "Chat History:\n",
    "{memory}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Review the chat history above carefully\n",
    "2. Identify new information about the user, such as:\n",
    "   - Personal details (name, location)\n",
    "   - Preferences (likes, dislikes)\n",
    "   - Interests and hobbies\n",
    "   - Past experiences\n",
    "   - Goals or future plans\n",
    "3. Merge any new information with existing memory\n",
    "4. Format the memory as a clear, bulleted list\n",
    "5. If new information conflicts with existing memory, keep the most recent version\n",
    "\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "\n",
    "Based on the chat history below above, please update the existing memory:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    key = \"user_memory\"\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    # Extract the actual memory content if it exists and add a prefix\n",
    "    if existing_memory:\n",
    "        # Value is a dictionary with a memory key\n",
    "        existing_memory_content = existing_memory.value.get('memory')\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)\n",
    "    \n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "    print(f\">>> response: {response}\")\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "    print(f\">>> existing_memory: {existing_memory}\")\n",
    "        \n",
    "    # Extract the memory\n",
    "    if existing_memory:\n",
    "        existing_memory_content = existing_memory.value.get('memory')\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
    "    print(f\">>> new memory: {new_memory}\")\n",
    "\n",
    "    # Overwrite the existing memory in the store \n",
    "    key = \"user_memory\"\n",
    "\n",
    "    # Write value as a dictionary with a memory key\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    print(f\">>> Saved Memory: {new_memory.content}\")\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is kim\n",
      ">>> response: content=\"Nice to meet you, Kim. I don't have any prior memory of our interactions, so this is the start of our conversation. How can I assist you today?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 86, 'total_tokens': 121, 'completion_time': 0.046666667, 'prompt_time': 0.005378299, 'queue_time': 0.010187871000000001, 'total_time': 0.052044966}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None} id='run-2bceaf99-549f-47f0-8802-5bc57c4ae18b-0' usage_metadata={'input_tokens': 86, 'output_tokens': 35, 'total_tokens': 121}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Kim. I don't have any prior memory of our interactions, so this is the start of our conversation. How can I assist you today?\n",
      ">>> existing_memory: None\n",
      ">>> new memory: content='' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 228, 'total_tokens': 229, 'completion_time': 0.001333333, 'prompt_time': 0.018102592, 'queue_time': -9223372036.872879, 'total_time': 0.019435925}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None} id='run-8ae5b82c-76a2-41b7-8a10-26b23c13e859-0' usage_metadata={'input_tokens': 228, 'output_tokens': 1, 'total_tokens': 229}\n",
      ">>> Saved Memory: \n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is kim\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around Seoul\n",
      ">>> response: content=\"Seoul is a great city to explore by bike. I've learned that you're interested in biking around Seoul, so I can provide you with some recommendations. Have you considered visiting the Cheonggyecheon Stream, which is a popular spot for cycling and offers a scenic route through the city? Or perhaps you'd like to explore the Seoul Bike Path, which is a 700km network of bike lanes and paths that crisscross the city?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 131, 'total_tokens': 223, 'completion_time': 0.122666667, 'prompt_time': 0.014821235, 'queue_time': 0.001923546, 'total_time': 0.137487902}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None} id='run-a4eed400-4c06-4662-9415-9bce34071b74-0' usage_metadata={'input_tokens': 131, 'output_tokens': 92, 'total_tokens': 223}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Seoul is a great city to explore by bike. I've learned that you're interested in biking around Seoul, so I can provide you with some recommendations. Have you considered visiting the Cheonggyecheon Stream, which is a popular spot for cycling and offers a scenic route through the city? Or perhaps you'd like to explore the Seoul Bike Path, which is a 700km network of bike lanes and paths that crisscross the city?\n",
      ">>> existing_memory: <langgraph.store.base.Item object at 0x000002963A663420>\n",
      ">>> new memory: content='' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 330, 'total_tokens': 331, 'completion_time': 0.001333333, 'prompt_time': 0.037327989, 'queue_time': -9223372036.892105, 'total_time': 0.038661322}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None} id='run-e9a4c372-e772-4d91-a17e-e3a58cffa7b3-0' usage_metadata={'input_tokens': 330, 'output_tokens': 1, 'total_tokens': 331}\n",
      ">>> Saved Memory: \n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around Seoul\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is kim\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Kim. I don't have any prior memory of our interactions, so this is the start of our conversation. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around Seoul\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Seoul is a great city to explore by bike. I've learned that you're interested in biking around Seoul, so I can provide you with some recommendations. Have you considered visiting the Cheonggyecheon Stream, which is a popular spot for cycling and offers a scenic route through the city? Or perhaps you'd like to explore the Seoul Bike Path, which is a 700km network of bike lanes and paths that crisscross the city?\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "state = graph.get_state(thread).values\n",
    "for m in state[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<langgraph.store.base.Item object at 0x0000029639AE21B0>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'value': {'memory': ''},\n",
       " 'key': 'user_memory',\n",
       " 'namespace': ['memory', '1'],\n",
       " 'created_at': '2024-11-23T10:23:55.559394+00:00',\n",
       " 'updated_at': '2024-11-23T10:23:57.437683+00:00'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.search(namespace)\n",
    "print(existing_memory)\n",
    "existing_memory[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langgraph.store.base.Item object at 0x0000029639AE21B0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'value': {'memory': ''},\n",
       " 'key': 'user_memory',\n",
       " 'namespace': ['memory', '1'],\n",
       " 'created_at': '2024-11-23T10:23:55.559394+00:00',\n",
       " 'updated_at': '2024-11-23T10:23:57.437683+00:00'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "print(existing_memory)\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We supply a user ID for across-thread memory as well as a new thread ID\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi! Where would you recommend that I go biking?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
