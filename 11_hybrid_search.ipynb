{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import ollama\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vectordb_as_df(db_path:str):\n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "    for collection in client.list_collections():\n",
    "        data = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "        df = pd.DataFrame({\"ids\":data[\"ids\"], \n",
    "                            \"metadatas\":data[\"metadatas\"], \n",
    "                            \"documents\":data[\"documents\"]})\n",
    "        df[\"first_div\"] = df[\"metadatas\"].apply(lambda x: x[\"First Division\"])\n",
    "        df[\"second_div\"] = df[\"metadatas\"].apply(lambda x: x[\"Second Division\"])\n",
    "        df[\"filename\"] = df[\"metadatas\"].apply(lambda x: x[\"File Name\"])\n",
    "        df = df[[\"ids\", \"first_div\", \"second_div\",\"filename\",\"documents\", \"metadatas\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_chroma.vectorstores.Chroma object at 0x000001EB93C0FC50>\n"
     ]
    }
   ],
   "source": [
    "db_path = \"./db/chroma_db_02\"\n",
    "vector_store = Chroma(collection_name=\"my_collection\", persist_directory=db_path, embedding_function=OllamaEmbeddings(model=\"bge-m3:latest\"))\n",
    "print(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>first_div</th>\n",
       "      <th>second_div</th>\n",
       "      <th>filename</th>\n",
       "      <th>documents</th>\n",
       "      <th>metadatas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faace8c4-ab2c-43b4-9b4e-7fc15319bc78</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Common</td>\n",
       "      <td>[KISA Insight 2023 Vol.03] ChatGPT(챗GPT) 보ᄋ...</td>\n",
       "      <td>This page explains [KISA Insight 2023 Vol.03] ...</td>\n",
       "      <td>{'File Name': '[KISA Insight 2023 Vol.03] Chat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a3d1b93-e5d3-4a96-990d-e4ba6b976e29</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Common</td>\n",
       "      <td>[KISA Insight 2023 Vol.03] ChatGPT(챗GPT) 보ᄋ...</td>\n",
       "      <td>This page explains [KISA Insight 2023 Vol.03] ...</td>\n",
       "      <td>{'File Name': '[KISA Insight 2023 Vol.03] Chat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ids first_div second_div  \\\n",
       "0  faace8c4-ab2c-43b4-9b4e-7fc15319bc78    MANUAL     Common   \n",
       "1  1a3d1b93-e5d3-4a96-990d-e4ba6b976e29    MANUAL     Common   \n",
       "\n",
       "                                            filename  \\\n",
       "0  [KISA Insight 2023 Vol.03] ChatGPT(챗GPT) 보ᄋ...   \n",
       "1  [KISA Insight 2023 Vol.03] ChatGPT(챗GPT) 보ᄋ...   \n",
       "\n",
       "                                           documents  \\\n",
       "0  This page explains [KISA Insight 2023 Vol.03] ...   \n",
       "1  This page explains [KISA Insight 2023 Vol.03] ...   \n",
       "\n",
       "                                           metadatas  \n",
       "0  {'File Name': '[KISA Insight 2023 Vol.03] Chat...  \n",
       "1  {'File Name': '[KISA Insight 2023 Vol.03] Chat...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_vectordb_as_df(db_path=db_path)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = \"I like a apple\"\n",
    "# response = ollama.embeddings(model=\"bge-m3:latest\", prompt=d)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47166, 44995, 53152, ..., 30774, 28023,  5082], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "def get_similarity_search_score_rank(query:str, db_path:str):\n",
    "    embedded_query = ollama.embeddings(model=\"bge-m3:latest\", prompt=query)\n",
    "    embedded_query=[np.float64(k) for k in embedded_query['embedding']]\n",
    "\n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "    for collection in client.list_collections():\n",
    "        data = collection.get(include=['embeddings'])\n",
    "    \n",
    "    results = []\n",
    "    for d in data['embeddings']:\n",
    "        similarity = cos_sim(embedded_query, d)\n",
    "        results.append(similarity)\n",
    "\n",
    "    results = [r.item() for r in results]\n",
    "\n",
    "    sorted_indices = np.argsort(results)  # 값에 대한 정렬된 인덱스\n",
    "    order_values = np.empty_like(sorted_indices)\n",
    "    order_values[sorted_indices] = np.arange(len(results))\n",
    "\n",
    "    return order_values\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "what is the noon report in iss system?\n",
    "\"\"\"\n",
    "res1 = get_similarity_search_score_rank(query=query, db_path=db_path)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53790"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'noon', 'report', 'iss']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0, 35667, 35668, ..., 17868,  8965, 52566], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def bm25_search_rank(query:str, db_path:str):\n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "    for collection in client.list_collections():\n",
    "        data = collection.get(include=['documents', 'metadatas'])\n",
    "    tokenized_corpus = [doc.split(\" \") for doc in data[\"documents\"]]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    pattern = r'\"(.*?)\"'  # 따옴표로 둘러싸인 단어만 검색 대상으로 리스트에 담기\n",
    "    tokenized_query = re.findall(pattern, query)\n",
    "    print(tokenized_query)\n",
    "\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    sorted_indices = np.argsort(doc_scores)  # 값에 대한 정렬된 인덱스\n",
    "    order_values = np.empty_like(sorted_indices)\n",
    "    order_values[sorted_indices] = np.arange(len(doc_scores))\n",
    "\n",
    "\n",
    "    return order_values\n",
    "\n",
    "res2 = bm25_search_rank(query='\"what\" is the \"noon\" \"report\" in \"iss\" system', db_path=\"./db/chroma_db_02\")\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53790"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf(all_rankings: list[list[int]]):\n",
    "    \"\"\"Takes in list of rankings produced by multiple retrieval algorithms,\n",
    "    and returns newly of ranked and scored items.\"\"\"\n",
    "    scores = {} # key is the index and value is the score of that index\n",
    "    # 1. Take every retrieval algorithm ranking\n",
    "    for algorithm_ranks in all_rankings:\n",
    "        # 2. For each ranking, take the index and the ranked position\n",
    "        for rank, idx in enumerate(algorithm_ranks):\n",
    "            # 3. Calculate the score and add it to the index\n",
    "            if idx in scores:\n",
    "                scores[idx] += 1 / (60 + rank)\n",
    "            else:\n",
    "                scores[idx] = 1 / (60 + rank)\n",
    "\n",
    "    # 4. Sort the indices based on accumulated scores\n",
    "    sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(35429, 0.01699409210619973),\n",
       " (47166, 0.016729158855143107),\n",
       " (0, 0.016721766121182067),\n",
       " (44995, 0.016431307068236697),\n",
       " (35667, 0.0164252958433114),\n",
       " (53152, 0.016183638275647654),\n",
       " (35668, 0.01615240548169952),\n",
       " (35669, 0.015965420234501735),\n",
       " (35670, 0.015666296716911006),\n",
       " (193, 0.01565292672028597)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ranks = rrf([res1, res2])\n",
    "new_ranks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File Name': 'Integrated Smart Ship(ISS1.0)',\n",
       " 'File Path': '/content/drive/MyDrive/MANUAL/Integrated Smart Ship(ISS)/Integrated Smart Ship(ISS1.0).pdf',\n",
       " 'First Division': 'MANUAL',\n",
       " 'Page': 89,\n",
       " 'Second Division': 'Integrated Smart Ship(ISS)'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"metadatas\"][193]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File Name': 'RULES FOR THE CLASSIFICATION OF STEEL SHIPS_467-NR_PartC_2024-07',\n",
       " 'File Path': '/content/drive/MyDrive/Rules/BV/RULES FOR THE CLASSIFICATION OF STEEL SHIPS_467-NR_PartC_2024-07.pdf',\n",
       " 'First Division': 'Rules',\n",
       " 'Page': 48,\n",
       " 'Second Division': 'BV'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"metadatas\"][47166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File Name': '[KISA Insight 2023 Vol.03] ChatGPT(챗GPT) 보안 위협과 시사점',\n",
       " 'File Path': '/content/drive/MyDrive/MANUAL/Common/[KISA Insight 2023 Vol.03] ChatGPT(챗GPT) 보안 위협과 시사점.pdf',\n",
       " 'First Division': 'MANUAL',\n",
       " 'Page': 0,\n",
       " 'Second Division': 'Common'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"metadatas\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
